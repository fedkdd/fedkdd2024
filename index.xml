<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FedKDD 2024</title>
    <link>https://fedkdd.github.io/fedkdd2024/</link>
    <description>Recent content on FedKDD 2024</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://fedkdd.github.io/fedkdd2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Terms &amp; Conditions</title>
      <link>https://fedkdd.github.io/fedkdd2024/terms-and-conditions/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/fedkdd2024/terms-and-conditions/</guid>
      <description>1. Definitions We collect certain identifying personal data when you sign up to our Service such as your name, email address, PayPal address (if different from email address), and telephone number. The personal data we collect from you is disclosed only in accordance with our Terms of Service and/or this Privacy Policy.Conclude collects Slack account and access information from Users for the purposes of connecting to the Slack API and to authenticate access to information on the Conclude website.</description>
    </item>
    
    <item>
      <title>Accepted Papers</title>
      <link>https://fedkdd.github.io/fedkdd2024/papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/fedkdd2024/papers/</guid>
      <description>Oral  Subgraph Federated Learning for Local Generalization. Sungwon Kim, Yoonho Lee, Carl Yang, Yunhak Oh, Namkyeong Lee, Sukwon Yun, Junseok Lee, Sein Kim, Chanyoung Park  Poster Cooperative Multiple Model Training for Personalized Federated Learning over Heterogeneous Devices. Jian Xu, Shuo Wan, Yinchuan Li, Zhilin Chen, yunfeng shao, Zhitang Chen, Shao-Lun Huang Towards Federated Learning with on-device Training and Communication in 8-bit Floating Point. Bokun Wang, Axel Berg, Durmus Alp Emre Acar, Chuteng Zhou FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning.</description>
    </item>
    
    <item>
      <title>Call for Submissions</title>
      <link>https://fedkdd.github.io/fedkdd2024/calls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/calls/</guid>
      <description>Workshop Scope The workshop will delve into both foundational and advanced issues in FL, incorporating a focus on graph analytics within the following four categories. Different from the previous workshops, FedGraph at ICDM 2023 or Federated Learning for Distributed Data Mining at KDD 2023, the workshop will bring in new challenges accompanied by the emergence of large models, generative AI, and new interdisciplinary applications in science.
(1) Scalability of FL facing increasingly larger and more heterogenous data, models, and computation-or-communication resources.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://fedkdd.github.io/fedkdd2024/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/fedkdd2024/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Keynotes</title>
      <link>https://fedkdd.github.io/fedkdd2024/speakers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/speakers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Organizers</title>
      <link>https://fedkdd.github.io/fedkdd2024/organizers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/organizers/</guid>
      <description>Workshop Committees  Junyuan Hong, Michigan State University  </description>
    </item>
    
    <item>
      <title>Panelist</title>
      <link>https://fedkdd.github.io/fedkdd2024/panel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/panel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Schedules</title>
      <link>https://fedkdd.github.io/fedkdd2024/schedules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fedkdd.github.io/schedules/</guid>
      <description>Workshop Schedule (Room 118)  Time Event Details Event --   2:00 pm - 2:10 pm  Opening Ceremony    2:10 pm - 2:50 am  Keynote Talk 1: Yong Chen  PDA: Privacy-preserving Distributed Algorithms and statistical inference in the era of real-world data networks   2:50 pm - 3:30 pm  Keynote Talk 2: Sebastian Stich  Local Update Methods for Federated Optimization   3:30 pm - 3:40 pm  Oral Presentation Subgraph Federated Learning for Local Generalization   3:40 pm - 3:50 pm  Coffee Break    3:50 pm - 4:20 pm  Poster Presentation Location: Area 118 at Bi-Color Foyer   4:20 am - 5:00 am  Keynote Talk 3: Jundong Li Data-Efficient Federated Learning: Harnessing the Power of Small Data   5:00 am - 5:40 pm  Keynote Talk 4: Graham Cormode Federated Computation Beyond Learning   5:40 pm - 6:00 pm  Panel Discussion Panelist: Jundong Li, Graham Cormode, Sebastian Stich, Yunfei Xu Moderator: Carl Yang   6:00 pm - 6:10 pm  Award Ceremony and Closing Session     </description>
    </item>
    
  </channel>
</rss>
